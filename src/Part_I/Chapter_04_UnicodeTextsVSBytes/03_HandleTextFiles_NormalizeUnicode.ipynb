{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc7b134",
   "metadata": {},
   "source": [
    "# Chapter 4. Unicode Text Versus Bytes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf097d",
   "metadata": {},
   "source": [
    "## ToC\n",
    "\n",
    "1. [Handling Text Files](#handling-text-files)\n",
    "2. [Normalizing Unicode for Reliable Comparisons](#normalizing-unicode-for-reliable-comparisons)  \n",
    "    2.1.[Case Folding](#case-folding)  \n",
    "    2.2.[Utility Functions for Normalized Text Matching](#utility-functions-for-normalized-text-matching)  \n",
    "    2.3.[Extreme “Normalization”: Taking Out Diacritics](#extreme-normalization-taking-out-diacritics)  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be24c4",
   "metadata": {},
   "source": [
    "## Handling Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee7611",
   "metadata": {},
   "source": [
    "The best practice for handling text I/O is the “Unicode sandwich”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db2bf1",
   "metadata": {},
   "source": [
    "![Figure 64](https://raw.githubusercontent.com/berserkhmdvhb/Training-Python/main/figures/Part_I/64.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856fc35",
   "metadata": {},
   "source": [
    "This means that `bytes` should be decoded to `str` as early as possible on input (e.g., when opening a file for reading). The “filling” of the sandwich is the business logic of your program, where text handling is done exclusively on `str` objects. You should never be encoding or decoding in the middle of other processing. On output, the `str` are encoded to `bytes` as late as possible. Most web frameworks work like that, and we rarely touch `bytes` when using them. In Django, for example, your views should output Unicode `str`; Django itself takes care of encoding the response to `bytes`, using UTF-8 by default.\n",
    "\n",
    "\n",
    "Python 3 makes it easier to follow the advice of the Unicode sandwich, because the `open()` built-in does the necessary decoding when reading and encoding when writing files in text mode, so all you get from `my_file.read()` and pass to `my_file.write(text)` are `str` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6c264",
   "metadata": {},
   "source": [
    "**Example:** A platform encoding issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbea01f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('cafe.txt', 'w', encoding='utf_8').write('café')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8728c894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafÃ©'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('cafe.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f566814",
   "metadata": {},
   "source": [
    "**The bug:** I specified UTF-8 encoding when writing the file but failed to do so when\n",
    "reading it, so Python assumed Windows default file encoding—code page 1252—and\n",
    "the trailing bytes in the file were decoded as characters `Ã©` instead of `é`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49fe8a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf_8'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open('cafe.txt', 'w', encoding='utf_8')\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30c15d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf_8'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d9de7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write('café')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9403e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ed9a5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.stat('cafe.txt').st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8d2d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2 = open('cafe.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ec7a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5dd87b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cp1252'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp2.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "925d7d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafÃ©'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a1b5301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='utf_8'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp3 = open('cafe.txt', encoding='utf_8')\n",
    "fp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "274c1856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp3.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fc6e3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='cafe.txt'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp4 = open('cafe.txt', 'rb')\n",
    "fp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86c00cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp4.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6efb9",
   "metadata": {},
   "source": [
    "![Figure 65](https://raw.githubusercontent.com/berserkhmdvhb/Training-Python/main/figures/Part_I/65.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d39c1",
   "metadata": {},
   "source": [
    "![Figure 66](https://raw.githubusercontent.com/berserkhmdvhb/Training-Python/main/figures/Part_I/66.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80476c7",
   "metadata": {},
   "source": [
    "### Beware of Encoding Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b40f7",
   "metadata": {},
   "source": [
    "The following output is from a Jupyter Noteobook, executed in VS Code, on Windows 10. To see more details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff08fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       OS: Windows\n",
      "               OS Version: 10.0.19045\n",
      "                 Platform: Windows-10-10.0.19045-SP0\n",
      "             Architecture: ('64bit', 'WindowsPE')\n",
      "                  Machine: AMD64\n",
      "                Processor: Intel64 Family 6 Model 186 Stepping 3, GenuineIntel\n",
      "           Python Version: 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)]\n",
      "        Python Executable: c:\\Users\\HamedVAHEB\\Documents\\Training\\Python\\FluentPython\\repo\\Training-Python\\env_train\\Scripts\\python.exe\n",
      "Python Encoding (Preferred): cp1252\n",
      "      Filesystem Encoding: utf-8\n",
      "         Default Encoding: utf-8\n",
      "   Terminal stdout is TTY: False\n",
      " Terminal stdout Encoding: UTF-8\n",
      "    Terminal stdin is TTY: False\n",
      "  Terminal stdin Encoding: utf-8\n",
      "   Terminal stderr is TTY: False\n",
      " Terminal stderr Encoding: UTF-8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import locale\n",
    "\n",
    "def get_environment_info():\n",
    "    info = {\n",
    "        \"OS\": platform.system(),\n",
    "        \"OS Version\": platform.version(),\n",
    "        \"Platform\": platform.platform(),\n",
    "        \"Architecture\": platform.architecture(),\n",
    "        \"Machine\": platform.machine(),\n",
    "        \"Processor\": platform.processor(),\n",
    "        \"Python Version\": sys.version,\n",
    "        \"Python Executable\": sys.executable,\n",
    "        \"Python Encoding (Preferred)\": locale.getpreferredencoding(),\n",
    "        \"Filesystem Encoding\": sys.getfilesystemencoding(),\n",
    "        \"Default Encoding\": sys.getdefaultencoding(),\n",
    "       #\"Environment Variables\": dict(os.environ),\n",
    "        \"Terminal stdout is TTY\": sys.stdout.isatty(),\n",
    "        \"Terminal stdout Encoding\": sys.stdout.encoding,\n",
    "        \"Terminal stdin is TTY\": sys.stdin.isatty(),\n",
    "        \"Terminal stdin Encoding\": sys.stdin.encoding,\n",
    "        \"Terminal stderr is TTY\": sys.stderr.isatty(),\n",
    "        \"Terminal stderr Encoding\": sys.stderr.encoding,\n",
    "    }\n",
    "    return info\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_info = get_environment_info()\n",
    "    for key, value in env_info.items():\n",
    "        print(f\"{key:>25}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866cad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'cp1252'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'cp1252'\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> 'utf-8'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "import sys\n",
    "expressions = \"\"\"\n",
    "locale.getpreferredencoding()\n",
    "type(my_file)\n",
    "my_file.encoding\n",
    "sys.stdout.isatty()\n",
    "sys.stdout.encoding\n",
    "sys.stdin.isatty()\n",
    "sys.stdin.encoding\n",
    "sys.stderr.isatty()\n",
    "sys.stderr.encoding\n",
    "sys.getdefaultencoding()\n",
    "sys.getfilesystemencoding()\n",
    "\n",
    "\"\"\"\n",
    "my_file = open('dummy', 'w')\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(f'{expression:>30} -> {value!r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66667eae",
   "metadata": {},
   "source": [
    "The output of the previous example on GNU/Linux (Ubuntu 14.04 to 19.10) and macOS (10.9 to 10.14) is identical, showing that UTF-8 is used everywhere in these systems:\n",
    "\n",
    "```python\n",
    "$ python3 default_encodings.py\n",
    "locale.getpreferredencoding() -> 'UTF-8'\n",
    "type(my_file) -> <class '_io.TextIOWrapper'>\n",
    "my_file.encoding -> 'UTF-8'\n",
    "sys.stdout.isatty() -> True\n",
    "sys.stdout.encoding -> 'utf-8'\n",
    "sys.stdin.isatty() -> True\n",
    "sys.stdin.encoding -> 'utf-8'\n",
    "sys.stderr.isatty() -> True\n",
    "sys.stderr.encoding -> 'utf-8'\n",
    "sys.getdefaultencoding() -> 'utf-8'\n",
    "sys.getfilesystemencoding() -> 'utf-8'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72240168",
   "metadata": {},
   "source": [
    "### Normalizing Unicode for Reliable Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723c139",
   "metadata": {},
   "source": [
    "String comparisons are complicated by the fact that Unicode has combining characters:\n",
    "diacritics and other marks that attach to the preceding character, appearing as\n",
    "one when printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fa1058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('café', 'café')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\N{COMBINING ACUTE ACCENT}'\n",
    "s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd0e3fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "771125b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c09a08",
   "metadata": {},
   "source": [
    "Placing `COMBINING ACUTE ACCENT` (U+0301) after `e` renders `é`. In the Unicode standard, sequences like `é` and `e\\u0301` are called *canonical equivalents* and applications are supposed to treat them as the same. But Python sees two different sequences of code points, and considers them not equal.\n",
    "\n",
    "The solution is `unicodedata.normalize()`. The first argument to that function is one of four strings: `'NFC'`, `'NFD'`, `'NFKC'`, and `'NFKD'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6185403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\N{COMBINING ACUTE ACCENT}'\n",
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b83c344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFC', s1)), len(normalize('NFC', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21b6d6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFD', s1)), len(normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51a8097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', s1) == normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4ba19",
   "metadata": {},
   "source": [
    "NFC is also the normalization form recommended by the W3C in [\"Character Model for the World Wide Web: String\n",
    "Matching and Searching\"](https://www.w3.org/TR/charmod-norm/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5408b7",
   "metadata": {},
   "source": [
    "Some single characters are normalized by NFC into another single character. The\n",
    "symbol for the ohm (`Ω`) unit of electrical resistance is normalized to the Greek uppercase\n",
    "omega. They are visually identical, but they compare as unequal, so it is essential\n",
    "to normalize to avoid surprises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10f61751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OHM SIGN'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "ohm = '\\u2126'\n",
    "name(ohm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d98bf58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK CAPITAL LETTER OMEGA'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm_c = normalize('NFC', ohm)\n",
    "name(ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78ec423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm == ohm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7d5fb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', ohm) == normalize('NFC', ohm_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd24f8a",
   "metadata": {},
   "source": [
    "The other two normalization forms are NFKC and NFKD, where the letter K stands\n",
    "for “compatibility.” These are stronger forms of normalization, affecting the so-called\n",
    "“compatibility characters.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a294afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "½\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "half = '\\N{VULGAR FRACTION ONE HALF}'\n",
    "print(half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fe75d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1⁄2'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFKC', half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13a0e52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tDIGIT ONE\n",
      "⁄\tFRACTION SLASH\n",
      "2\tDIGIT TWO\n"
     ]
    }
   ],
   "source": [
    "for char in normalize('NFKC', half):\n",
    "    print(char, name(char), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9f6857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_squared = '4²'\n",
    "normalize('NFKC', four_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4b2faf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('μ', 'μ')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = 'μ'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "micro, micro_kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ee3218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 956)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(micro), ord(micro_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0ac5776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GREEK SMALL LETTER MU', 'GREEK SMALL LETTER MU')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name(micro), name(micro_kc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004f5f3",
   "metadata": {},
   "source": [
    "![Figure 67](https://raw.githubusercontent.com/berserkhmdvhb/Training-Python/main/figures/Part_I/67.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be34d6f",
   "metadata": {},
   "source": [
    "### Case Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15510b",
   "metadata": {},
   "source": [
    "Case folding is essentially converting all text to lowercase, with some additional transformations. It is supported by the `str.casefold()` method.\n",
    "\n",
    "For any string `s` containing only `latin1` characters, `s.casefold()` produces the same result as `s.lower()`, with only two exceptions—the micro sign `'μ'` is changed to the Greek lowercase `mu` (which looks the same in most fonts) and the German Eszett or\n",
    "`\"sharp s\"` (`ß`) becomes `\"ss\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "761aa649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = 'A'\n",
    "str2 = str1.casefold()\n",
    "str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a290425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK SMALL LETTER MU'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = 'μ'\n",
    "name(micro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c15904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK SMALL LETTER MU'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_cf = micro.casefold()\n",
    "name(micro_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73e59be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('μ', 'μ')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro, micro_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b41a4d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN SMALL LETTER SHARP S'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett = 'ß'\n",
    "name(eszett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46f33acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ß', 'ss')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett_cf = eszett.casefold()\n",
    "eszett, eszett_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10453380",
   "metadata": {},
   "source": [
    "There are nearly 300 code points for which `str.casefold()` and `str.lower()` return different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cfe9e",
   "metadata": {},
   "source": [
    "NFC is the best normalized form for most applications. `str.casefold()` is the way to go for case-insensitive comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53c493",
   "metadata": {},
   "source": [
    "### Utility Functions for Normalized Text Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d60b1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions for normalized Unicode string comparison.\n",
    "Using Normal Form C, case sensitive:\n",
    ">>> s1 = 'café'\n",
    ">>> s2 = 'cafe\\u0301'\n",
    ">>> s1 == s2\n",
    "False\n",
    ">>> nfc_equal(s1, s2)\n",
    "True\n",
    ">>> nfc_equal('A', 'a')\n",
    "False\n",
    "Using Normal Form C with case folding:\n",
    ">>> s3 = 'Straße'\n",
    ">>> s4 = 'strasse'\n",
    ">>> s3 == s4\n",
    "False\n",
    ">>> nfc_equal(s3, s4)\n",
    "False\n",
    ">>> fold_equal(s3, s4)\n",
    "True\n",
    ">>> fold_equal(s1, s2)\n",
    "True\n",
    ">>> fold_equal('A', 'a')\n",
    "True\n",
    "\"\"\"\n",
    "from unicodedata import normalize\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() ==\n",
    "            normalize('NFC', str2).casefold())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9580d4bc",
   "metadata": {},
   "source": [
    "#### Extreme “Normalization”: Taking Out Diacritics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8793f2",
   "metadata": {},
   "source": [
    "The Google Search secret sauce involves many tricks, but one of them apparently is\n",
    "ignoring diacritics (e.g., accents, cedillas, etc.), at least in some contexts. Removing\n",
    "diacritics is not a proper form of normalization because it often changes the meaning\n",
    "of words and may produce false positives when searching. But it helps coping with\n",
    "some facts of life: people sometimes are lazy or ignorant about the correct use of diacritics,\n",
    "and spelling rules change over time, meaning that accents come and go in living\n",
    "languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf05768",
   "metadata": {},
   "source": [
    "**Diacritics VS Combining Marks**\n",
    "\n",
    " Diacritics are marks added to letters to alter their pronunciation or to distinguish between similar words.\n",
    "\n",
    "\n",
    " Combining marks are Unicode characters that combine with the preceding base character to visually form a single glyph with a diacritic.\n",
    "\n",
    "| Aspect             | Diacritics                                 | Combining Marks                             |\n",
    "|--------------------|---------------------------------------------|---------------------------------------------|\n",
    "| Concept            | Linguistic / Orthographic                  | Encoding / Digital representation           |\n",
    "| Role               | Modify pronunciation or meaning            | Modify appearance of base character         |\n",
    "| Unicode            | May be a **precomposed character** (e.g., `é` = U+00E9) | Typically a **separate character** that follows the base (e.g., `e` + U+0301) |\n",
    "| Usage              | Used in natural languages                  | Used in digital text to represent diacritics |\n",
    "| Example            | `é`, `ñ` (single character)                | `e` + `́`, `n` + `̃` (two characters visually combined) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be5514d",
   "metadata": {},
   "source": [
    "**Example:** function to remove all combining marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a1872",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4f325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é\n"
     ]
    }
   ],
   "source": [
    "s = 'e\\u0301'\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6fb2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eé\n"
     ]
    }
   ],
   "source": [
    "s = 'e\\u00e9'\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78d476d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    # Decompose all characters into base characters and combining marks.\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    # Filter out all combining marks.\n",
    "    shaved = ''.join(c for c in norm_txt\n",
    "        if not unicodedata.combining(c))\n",
    "    # Recompose all characters.\n",
    "    return unicodedata.normalize('NFC', shaved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7ca8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcbbc65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.”'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = '“Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.”'\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fccc06bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Herr Voß: • ½ cup of OEtker™ caffe latte • bowl of acai.”'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shave_marks(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "795edced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.”'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_normed = unicodedata.normalize('NFD', order)\n",
    "order_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3505a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_differences(s1: str, s2: str) -> list:\n",
    "    return [(i, c1, c2) for i, (c1, c2) in enumerate(zip(s1, s2)) if c1 != c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043cc79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34, 'è', 'e'),\n",
       " (35, ' ', '̀'),\n",
       " (36, 'l', ' '),\n",
       " (37, 'a', 'l'),\n",
       " (38, 't', 'a'),\n",
       " (40, 'e', 't'),\n",
       " (41, ' ', 'e'),\n",
       " (42, '•', ' '),\n",
       " (43, ' ', '•'),\n",
       " (44, 'b', ' '),\n",
       " (45, 'o', 'b'),\n",
       " (46, 'w', 'o'),\n",
       " (47, 'l', 'w'),\n",
       " (48, ' ', 'l'),\n",
       " (49, 'o', ' '),\n",
       " (50, 'f', 'o'),\n",
       " (51, ' ', 'f'),\n",
       " (52, 'a', ' '),\n",
       " (53, 'ç', 'a'),\n",
       " (54, 'a', 'c'),\n",
       " (55, 'í', '̧'),\n",
       " (56, '.', 'a'),\n",
       " (57, '”', 'i')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_differences(order, order_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8153f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34, 'è', 'e'), (53, 'ç', 'c'), (55, 'í', 'i')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_differences(order, shave_marks(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79f5eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import unicodedata\n",
    "\n",
    "def show_grapheme_differences(s1: str, s2: str):\n",
    "    g1 = regex.findall(r'\\X', s1)\n",
    "    g2 = regex.findall(r'\\X', s2)\n",
    "\n",
    "    for i, (c1, c2) in enumerate(zip(g1, g2)):\n",
    "        if c1 != c2:\n",
    "            print(f\"Position {i}:\")\n",
    "            print(f\"  Original   : {repr(c1)} → {[f'U+{ord(ch):04X}' for ch in c1]} ({[unicodedata.name(ch, 'UNKNOWN') for ch in c1]})\")\n",
    "            print(f\"  Normalized : {repr(c2)} → {[f'U+{ord(ch):04X}' for ch in c2]} ({[unicodedata.name(ch, 'UNKNOWN') for ch in c2]})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc282a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 34:\n",
      "  Original   : 'è' → ['U+00E8'] (['LATIN SMALL LETTER E WITH GRAVE'])\n",
      "  Normalized : 'è' → ['U+0065', 'U+0300'] (['LATIN SMALL LETTER E', 'COMBINING GRAVE ACCENT'])\n",
      "\n",
      "Position 53:\n",
      "  Original   : 'ç' → ['U+00E7'] (['LATIN SMALL LETTER C WITH CEDILLA'])\n",
      "  Normalized : 'ç' → ['U+0063', 'U+0327'] (['LATIN SMALL LETTER C', 'COMBINING CEDILLA'])\n",
      "\n",
      "Position 55:\n",
      "  Original   : 'í' → ['U+00ED'] (['LATIN SMALL LETTER I WITH ACUTE'])\n",
      "  Normalized : 'í' → ['U+0069', 'U+0301'] (['LATIN SMALL LETTER I', 'COMBINING ACUTE ACCENT'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_grapheme_differences(order, order_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1a3ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 34:\n",
      "  Original   : 'è' → ['U+0065', 'U+0300'] (['LATIN SMALL LETTER E', 'COMBINING GRAVE ACCENT'])\n",
      "  Normalized : 'e' → ['U+0065'] (['LATIN SMALL LETTER E'])\n",
      "\n",
      "Position 53:\n",
      "  Original   : 'ç' → ['U+0063', 'U+0327'] (['LATIN SMALL LETTER C', 'COMBINING CEDILLA'])\n",
      "  Normalized : 'c' → ['U+0063'] (['LATIN SMALL LETTER C'])\n",
      "\n",
      "Position 55:\n",
      "  Original   : 'í' → ['U+0069', 'U+0301'] (['LATIN SMALL LETTER I', 'COMBINING ACUTE ACCENT'])\n",
      "  Normalized : 'i' → ['U+0069'] (['LATIN SMALL LETTER I'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_grapheme_differences(order_normed, shave_marks(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c9cccd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ζεφυρος, Zefiro'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Greek = 'Ζέφυρος, Zéfiro'\n",
    "shave_marks(Greek)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb932c90",
   "metadata": {},
   "source": [
    "An even more radical step would be to replace common symbols in Western texts\n",
    "(e.g., curly quotes, em dashes, bullets, etc.) into ASCII equivalents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf3c2d",
   "metadata": {},
   "source": [
    "**Example:** Transform some Western typographical symbols into ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51f6ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    preserve = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue # ignore diacritic on Latin base char\n",
    "        preserve.append(c)\n",
    "        # if it isn't a combining char, it's a new base char\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(preserve)\n",
    "    return unicodedata.normalize('NFC', shaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1906f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mapping table for char-to-char replacement.\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„ˆ‹‘’“”•–—˜›\"\"\",\n",
    "\"\"\"'f\"^<''\"\"---~>\"\"\")\n",
    "\n",
    "# Build mapping table for char-to-string replacement.\n",
    "multi_map = str.maketrans({\n",
    "    '€': 'EUR',\n",
    "    '…': '...',\n",
    "    'Æ': 'AE',\n",
    "    'æ': 'ae',\n",
    "    'Œ': 'OE',\n",
    "    'œ': 'oe',\n",
    "    '™': '(TM)',\n",
    "    '‰': '<per mille>',\n",
    "    '†': '**',\n",
    "    '‡': '***', \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0615240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge mapping tables.\n",
    "multi_map.update(single_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c258a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06e26c",
   "metadata": {},
   "source": [
    "`dewinize` does not affect ASCII or latin1 text, only the Microsoft additions to latin1 in cp1252."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9f80087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asciize(txt):\n",
    "    # Apply dewinize and remove diacritical marks.\n",
    "    no_marks = shave_marks_latin(dewinize(txt))\n",
    "    # Replace the Eszett with “ss” (we are not using case fold here because we want to preserve the case).\n",
    "    no_marks = no_marks.replace('ß', 'ss')\n",
    "    # Apply NFKC normalization to compose characters with their compatibility code points.\n",
    "    return unicodedata.normalize('NFKC', no_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9f826c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = '“Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.”'\n",
    "dewinize(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d6df58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asciize(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42368c5",
   "metadata": {},
   "source": [
    "![Figure 68](https://raw.githubusercontent.com/berserkhmdvhb/Training-Python/main/figures/Part_I/68.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
